# Parser-Project

# Project Objective:
The parser project is divided into two stages: scanning and parsing. The scanner, accepts a string and converts it into a list of tokens. The input text is a C++ program made up of C++ statements, like: if, else if, for, while, variable/constant declarations, assignment, expressions and other statements. Expressions are addition, subtraction … etc. Here's how this project works: • The scanner takes a list of tokens and tests if it can be transformed into a list of statements, then takes the same list of tokens and tests if the tokens can be divided up into individual statements, each statement ending with a semicolon. • The parser tests if the first tokens of the token list make up a legal statement. If so, the statement is returned in a structure and the remaining tokens are tested again. For more details see Parsing1.pdf and Parsing2.pdf posted in D2L.
Requirements: 
1.	Parsing program for C++ like statements in Prolog language. 
2.	Documentation Report

# Introduction:

Parsing entails translating the input stream into words in the target language. A parser is often used as part of an interpreter or compiler. There are three stages to the parsing process:
1.	Lexical Analysis: A lexical analyzer is used to produce tokens from a stream of input
string characters, which are broken into small components to form meaningful
expressions.
2.	Syntactic Analysis: Checks whether the generated tokens form a meaningful expression.
This makes use of a context-free grammar that defines algorithmic procedures for
components. These work to form an expression and define the order in which tokens
must be placed.
3.	Semantic Parsing: The final parsing stage in which the meaning and implications of the
validated expression are determined, and necessary actions are taken.

The main goal of a parser is to see whether input data can be deduced from the grammar's start symbol. If that's the case, how can this input data be derived? This is accomplished in the following way:
•	Top-Down Parsing: Involves searching a parse tree to find the left most derivations of an input stream by using a top-down expansion. Examples include LL parsers and recursive-descent parsers.
•	Bottom-Up Parsing: Involves rewriting the input back to the start symbol. This type of parsing is also known as shift-reduce parsing. One example is a LR parser.

The inverse of templating is parsing: defining the structure and extracting the data. The inverse of templating is parsing: defining the structure and extracting the data. When parsing, the model must be determined from the raw representation. Parser may refer to both the program that performs the entire process and just the proper parser, which analyzes the tokens generated by the entire process and just the proper parser in the sense of parsing. Scanning and parsing are the two phases of the parser project. 

The scanner takes a string and turns it into a token list. The input text consists of C++ statements such as if, else, for, while, variable/constant declarations, assignment, expressions, and other statements. In any case, you're referring to the parser. Its output is typically a tree, which is an ordered code structure. A parse tree or an abstract syntax tree may be used. They're both trees, but the degree to which they reflect the actual code written and the parser's intermediate elements differs. The distinction between the two can be hazy at times; we'll look at their differences in more detail in a later paragraph.
The parser needs the lexer since it does not function directly on the text but rather on the lexer's performance. A lexer and a parser function in tandem: the lexer scans the input and generates matching tokens, while the parser scans the tokens and generates the parsing result. Parser may refer to both the program that performs the entire process and only the proper parser that analyzes the tokens provided by the lexer in the sense of parsing.

# Functions and data structures:
If else statements and do when statements were used. A list is a data structure that serves as a container for elements that can be added, removed, or used to perform operations within a sequence or iteration. There are facts, laws, and queries in prolog. Predicates are the terms used to describe the relationships between objects. When these relationships are believed to be valid all of the time, they can be considered truth. If and only if the predicate is valid, clauses are also the relation between objects. This is often referred to as a norm. Queries are what happen when a consumer asks a question about the truth.
